История теории вероятностей     История теории вероятностей отмечена многими уникальными особенностями. Прежде всего, в отличие от появившихся примерно в то же время других разделов математики (например, математического анализа или аналитической геометрии), у теории вероятностей по существу не было античных или средневековых предшественников, она целиком — создание Нового времени[1]. Долгое время теория вероятностей считалась чисто опытной наукой и «не совсем математикой»[2][3], её строгое обоснование было разработано только в 1929 году, то есть даже позже, чем аксиоматика теории множеств (1922). В наши дни теория вероятностей занимает одно из первых мест в прикладных науках по широте своей области применения; «нет почти ни одной естественной науки, в которой так или иначе не применялись бы вероятностные методы»[4]. Историки выделяют в развитии теории вероятностей несколько периодов[5][6].  Предыстория, до XVI века включительно. В античные времена и в Средневековье натурфилософы ограничивались метафизическими рассуждениями о происхождении случайности и её роли в природе[7]. Математики в этот период рассматривали и иногда решали задачи, связанные с теорией вероятностей, но никаких общих методов и тематических понятий ещё не появилось. Главным достижением данного периода можно считать развитие комбинаторных методов, которые позже пригодились создателям теории вероятностей. Начало формирования во второй половине XVII века основных понятий и методов теории вероятностей для случайных величин с конечным числом значений. Стимулом вначале служили преимущественно проблемы, возникающие в азартных играх, однако область применения теории вероятностей почти сразу начинает расширяться, включая в себя прикладные задачи демографической статистики, страхового дела и теории приближённых вычислений. На этом этапе важный вклад в идеи новой науки внесли Паскаль и Ферма. Гюйгенс ввёл два фундаментальных понятия: числовая мера вероятности события, а также понятие математического ожидания случайной величины. В XVIII веке появились монографии с систематическим изложением теории вероятностей. Первой из них стала книга Якоба Бернулли «Искусство предположений» (1713 год). В ней Бернулли предложил классическое определение вероятности случайного события как отношение числа равновероятных исходов, связанных с этим событием, к общему числу исходов. Он также изложил правила подсчёта вероятности для сложных событий и дал первый вариант ключевого «закона больших чисел», разъясняющего, почему частота события в серии испытаний не меняется хаотично, а в некотором смысле стремится к своему предельному теоретическому значению (то есть вероятности). Идеи Бернулли далеко развили в начале XIX века Лаплас, Гаусс, Пуассон. Применение вероятностных методов в прикладной статистике значительно расширилось. Понятие вероятности стало определено и для непрерывных случайных величин, благодаря чему появилась возможность применения методов математического анализа. Появляются первые попытки применения теории вероятностей в физике. К концу XIX века появляются статистическая физика, строгая теория ошибок измерения, вероятностные методы проникают в самые различные прикладные науки. В XX веке в физике была создана теория микромира, а в биологии — теория наследственности, обе они существенно основаны на вероятностных методах. Карл Пирсон разработал алгоритмы математической статистики, широко и повсеместно применяемые для анализа прикладных измерений, проверки гипотез и принятия решений. А. Н. Колмогоров дал классическую аксиоматику теории вероятностей. Из других новых областей применений теории вероятностей необходимо упомянуть теорию информации и теорию случайных процессов. Философские споры о том, что такое вероятность и в чём причина её устойчивости, продолжаются. Содержание  1 Средневековая Европа и начало Нового времени 2 XVII век: Паскаль, Ферма, Гюйгенс 3 XVIII век  3.1 «Искусство предположений» Якоба Бернулли 3.2 Развитие идей Бернулли   4 XIX век  4.1 Общие тенденции и критика 4.2 Гаусс, Лаплас, Пуассон 4.3 Теория ошибок измерения 4.4 Парадоксы Бертрана 4.5 Статистическая физика 4.6 Российская школа   5 XX век  5.1 Теоретические вопросы и математические методы 5.2 Создание математической статистики 5.3 Случайные процессы 5.4 Новые приложения 5.5 Обоснование и аксиоматизация   6 См. также 7 Примечания 8 Литература 9 Ссылки   Средневековая Европа и начало Нового времени[править | править код]  Древние образцы игральных костей Первые задачи вероятностного характера возникли в различных азартных играх — костях, картах и др.[8] Французский каноник XIII века Ришар де Фурниваль правильно подсчитал все возможные суммы очков после броска трёх костей и указал число способов, которыми может получиться каждая из этих сумм. Это число способов можно рассматривать как первую числовую меру ожидаемости события, аналогичную вероятности. До Фурниваля, а иногда и после него, эту меру часто подсчитывали неверно, считая, например, что суммы 3 и 4 очка равновероятны, так как оба могут получиться «только одним способом»: по результатам броска «три единицы» и «двойка с двумя единицами» соответственно. При этом не учитывалось, что три единицы в самом деле получаются только одним способом:     1 + 1 + 1   {\displaystyle 1+1+1}  , а двойка с двумя единицами — тремя:     1 + 1 + 2 ;  1 + 2 + 1 ;  2 + 1 + 1   {\displaystyle 1+1+2;\;1+2+1;\;2+1+1}  , так что эти события не равновероятны[9]. Аналогичные ошибки неоднократно встречались и в дальнейшей истории науки. В обширной математической энциклопедии «Сумма арифметики, геометрии, отношений и пропорций» итальянца Луки Пачоли (1494) содержатся оригинальные задачи на тему: как разделить ставку между двумя игроками, если серия игр прервана досрочно. Пример подобной задачи: игра идёт до 60 очков, победитель получает всю ставку в 22 дуката, в ходе игры первый игрок набрал 50 очков, второй — 30, и тут игру пришлось прекратить; требуется справедливо разделить исходную ставку. Решение зависит от того, что понимать под «справедливым» разделом; сам Пачоли предложил делить пропорционально набранным очкам (55/4 и 33/4 дуката)[10]; позднее его решение было признано ошибочным[11].   Распределение суммы очков после бросания двух костей Крупный алгебраист XVI века Джероламо Кардано посвятил анализу игры содержательную монографию «Книга об игре в кости» (1526 год, опубликована посмертно). Кардано провёл полный и безошибочный комбинаторный анализ для значений суммы очков и указал для разных событий ожидаемое значение доли «благоприятных» событий: например, при бросании трёх костей доля случаев, когда значения всех 3 костей совпадают, равна 6/216 или 1/36. Кардано сделал проницательное замечание: реальное количество исследуемых событий может при небольшом числе игр сильно отличаться от теоретического, но чем больше игр в серии, тем доля этого различия меньше. По существу, Кардано близко подошёл к понятию вероятности[12]: .mw-parser-output .ts-Начало_цитаты-quote{float:none;padding:0.25em 1em;border:thin solid #eaecf0}.mw-parser-output .ts-Начало_цитаты-source{margin:1em 0 0 5%;font-size:105%}.mw-parser-output .ts-Начало_цитаты-quote .ts-oq{margin:0 -1em -0.25em}.mw-parser-output .ts-Начало_цитаты-quote .ts-oq .NavFrame{padding:0}.mw-parser-output .ts-Начало_цитаты-quote .ts-oq .NavHead,.mw-parser-output .ts-Начало_цитаты-quote .ts-oq .NavContent{padding-left:1.052632em;padding-right:1.052632em}    Итак, имеется одно общее правило для расчёта: необходимо учесть общее число возможных выпадений и число способов, которыми могут появиться данные выпадения, а затем найти отношение последнего числа к числу оставшихся возможных выпадений.  .mw-parser-output .ts-Конец_цитаты-source{margin:0.357143em 2em 0 0;text-align:right} Другой итальянский алгебраист, Никколо Тарталья, раскритиковал подход Пачоли к решению задачи о разделе ставки: ведь если один из игроков ещё не успел набрать ни одного очка, то алгоритм Пачоли отдаёт всю ставку его сопернику, но это трудно назвать справедливым, поскольку некоторые шансы на выигрыш у отстающего всё же имеются. Кардано и Тарталья предложили свои (различные) способы раздела, но впоследствии и эти способы были признаны неудачными[13]. Исследованием данной темы занимался и Галилео Галилей, написавший трактат «О выходе очков при игре в кости» (1718 год, опубликован посмертно). Изложение теории игры у Галилея отличается исчерпывающей полнотой и ясностью. В своей главной книге «Диалог о двух главнейших системах мира, птоломеевой и коперниковой» Галилей также указал на возможность оценки погрешности астрономических и иных измерений, причём заявил, что малые ошибки измерения вероятнее, чем большие, отклонения в обе стороны равновероятны, а средний результат должен быть близок к истинному значению измеряемой величины. Эти качественные рассуждения стали первым в истории предсказанием нормального распределения ошибок[14].  XVII век: Паскаль, Ферма, Гюйгенс[править | править код]  Арифметический треугольник, основа комбинаторных исследований Паскаля В XVII веке начало формироваться отчётливое представление о проблематике теории вероятностей и появились первые математические (комбинаторные) методы решения вероятностных задач. Основателями математической теории вероятностей стали Блез Паскаль и Пьер Ферма[15]. Перед этим математик-любитель шевалье де Мере обратился к Паскалю по поводу так называемой «задачи об очках»: сколько раз нужно бросать две кости, чтобы ставить на одновременное выпадение хотя бы раз двух шестёрок было выгодно? Паскаль и Ферма вступили в переписку друг с другом по поводу данной задачи и родственных вопросов (1654). В рамках этой переписки учёные обсудили ряд проблем, связанных с вероятностными расчётами; в частности, рассматривалась старая задача о разделе ставки, и оба учёных пришли к решению, что надо разделить ставку соответственно остающимся шансам на выигрыш. Паскаль указал де Мере на ошибку, допущенную им при решении «задачи об очках»: в то время как де Мере неверно определил равновероятные события, получив ответ: 24 броска, Паскаль дал правильный ответ: 25 бросков[15][16]. Паскаль в своих трудах далеко продвинул применение комбинаторных методов, которые систематизировал в своей книге «Трактат об арифметическом треугольнике» (1665)[17]. Опираясь на вероятностный подход, Паскаль даже доказывал (в посмертно опубликованных заметках), что быть верующим выгоднее, чем атеистом (см. «пари Паскаля»).   Христиан Гюйгенс Тематика дискуссии Паскаля и Ферма (без подробностей) стала известна Христиану Гюйгенсу, который опубликовал собственное исследование «О расчётах в азартных играх» (1657): первый трактат по теории вероятностей[15]. В предисловии Гюйгенс пишет[18]:    Я полагаю, что при внимательном изучении предмета читатель заметит, что имеет дело не только с игрой, но что здесь закладываются основы очень интересной и глубокой теории. В трактате Гюйгенса подробно излагаются вопросы, рассмотренные Ферма и Паскалем, но ставятся и новые вопросы[11]. Главным достижением нидерландского учёного стало введение понятия математического ожидания, то есть теоретического среднего значения случайной величины. Гюйгенс также указал классический способ его подсчёта[18]:     Если число случаев, в которых получается сумма     a   {\displaystyle a}  , равно     p   {\displaystyle p}  , а число случаев, в которых получается сумма     b   {\displaystyle b}  , равно     q   {\displaystyle q}  , то стоимость моего ожидания равна        a p + b q   p + q      {\displaystyle {\frac {ap+bq}{p+q}}}  .   Гюйгенс, как видно из цитаты, вначале использовал термин «стоимость», а термин «ожидание» появился впервые при переводе трактата Гюйгенса Ван Схоутеном на латинский язык и стал общепринятым в науке[19]. В книге большое число задач, некоторые с решениями, другие «для самостоятельного решения». Из последних особый интерес и оживлённое обсуждение вызвала «задача о разорении игрока». В несколько обобщённом виде она формулируется так: у игроков A и B есть     a   {\displaystyle a}   и     b   {\displaystyle b}   монет соответственно, в каждой игре выигрывается одна монета, вероятность выигрыша A в каждой игре равна     p ,   {\displaystyle p,}   требуется найти вероятность полного его разорения. Полное общее решение «задачи о разорении» дал Абрахам де Муавр полвека спустя (1711)[20]. В наши дни вероятностная схема «задачи о разорении» используется при решении многих задач типа «случайное блуждание»[21]. Гюйгенс проанализировал и задачу о разделе ставки, дав её окончательное решение: ставку надо разделить пропорционально вероятностям выигрыша при продолжении игры[22]. Он также впервые применил вероятностные методы к демографической статистике и показал, как рассчитать среднюю продолжительность жизни[23]. К этому же периоду относятся публикации английских статистиков Джона Граунта (1662) и Уильяма Петти (1676, 1683). Обработав данные более чем за столетие, они показали, что многие демографические характеристики лондонского населения, несмотря на случайные колебания, имеют достаточно устойчивый характер — например, соотношение числа новорождённых мальчиков и девочек редко отклоняется от пропорции 14 к 13, невелики колебания и процента смертности от конкретных случайных причин. Эти данные подготовили научную общественность к восприятию новых идей[18]. Граунт также впервые составил таблицы смертности — таблицы вероятности смерти как функции возраста. Вопросами теории вероятностей и её применения к демографической статистике занялись также Иоганн Худде и Ян де Витт в Нидерландах, которые в 1671 году также составили таблицы смертности и использовали их для вычисления размеров пожизненной ренты. Более подробно данный круг вопросов был изложен в 1693 году Эдмундом Галлеем[11][24].  XVIII век[править | править код] На книгу Гюйгенса опирались появившиеся в начале XVIII века трактаты Пьера де Монмора «Опыт исследования азартных игр» (фр. Essay d'analyse sur les jeux de hazard; опубликован в 1708 и переиздан с дополнениями в 1713 году) и Якоба Бернулли «Искусство предположений» (лат. Ars conjectandi; опубликован уже после смерти учёного, в том же 1713 году). Последний имел для теории вероятностей особенно большое значение[11].  «Искусство предположений» Якоба Бернулли[править | править код]  Якоб Бернулли Базель, Исторический музей Над трактатом «Искусство предположений» Якоб Бернулли работал двадцать лет, уже лет за десять до публикации текст этого труда в виде незаконченной рукописи стал распространяться по Европе, вызывая большой интерес. Трактат стал первым систематическим изложением теории вероятностей. В этой книге автор привёл, в частности, классическое определение вероятности события как отношения числа исходов, связанных с этим событием, к общему числу исходов (у достоверного события вероятность равна единице, у невозможного — нулю). Систематически изученная Бернулли вероятностная схема сейчас называется биномиальным распределением[25]. Ранее математики чаще всего оперировали самим количеством исходов; историки полагают, что замена количества на «частоту» (то есть деление на общее количество исходов) была стимулирована статистическими соображениями: частота, в отличие от количества, обычно имеет тенденцию к стабилизации при увеличении числа наблюдений. Определение вероятности «по Бернулли» сразу стало общепринятым, его воспроизводили Абрахам де Муавр в книге «Учение о случаях» (1718) и все последующие математики. Единственное важное уточнение — о том, что все «элементарные исходы» обязаны быть равновероятны, — сделал Пьер-Симон Лаплас в 1812 году. Если для события невозможно подсчитать классическую вероятность (например, из-за отсутствия возможности выделить равновероятные исходы), то Бернулли предложил использовать статистический подход, то есть оценить вероятность по результатам наблюдений этого события или связанных с ним[25].   Трактат «Искусство предположений» В первой части своего трактата Бернулли полностью перепечатывает книгу Гюйгенса, которой он даёт самую высокую оценку, и существенно дополняет собственными комментариями. В частности, он приводит общую «формулу Бернулли»: если вероятность события равна     p   {\displaystyle p}  , то вероятность того, что в     n   {\displaystyle n}   испытаниях событие случится     m   {\displaystyle m}   раз, равна      C  n   m    p  m   ( 1 − p  )  n − m     {\displaystyle C_{n}^{m}p^{m}(1-p)^{n-m}}  . Далее Бернулли подробно излагает комбинаторику и на её основе решает несколько задач со случайным выбором. В последней части книги, оставшейся недописанной, Бернулли собирался рассмотреть экономические и другие практические приложения теории вероятностей[26]. Огромное значение как для теории вероятностей, так и для науки в целом имел доказанный Бернулли первый вариант закона больших чисел (название закону дал позже Пуассон)[27]. Этот закон объясняет, почему статистическая частота при увеличении числа наблюдений сближается с теоретическим её значением — вероятностью, и тем самым связывает два разных определения вероятности. В дальнейшем закон больших чисел трудами многих математиков был значительно обобщён и уточнён; как оказалось, стремление статистической частоты к теоретической отличается от стремления к пределу в анализе — частота может значительно отклоняться от ожидаемого предела, и можно только утверждать, что вероятность таких отклонений с ростом числа испытаний стремится к нулю. Вместе с тем отклонения частоты от вероятности также поддаются вероятностному анализу[28].  Развитие идей Бернулли[править | править код]  Трактат де Муавра«Учение о случаях» Трактат Якоба Бернулли вызвал резкий подъём интереса к вероятностным проблемам и рост числа исследований новых задач. Абрахам де Муавр опубликовал несколько работ, среди которых наиболее интересны статья «Об измерении случайности, или вероятностях результатов в азартных играх» (1711) и трактат «Учение о случаях» (1718), выдержавший в XVIII веке три издания. В этом трактате Муавр не только полностью решил упоминавшуюся выше «задачу о разорении игрока», но и оценил для неё среднюю продолжительность игры и вероятности выигрыша за заданное число игр для каждого игрока[11][29]. В другой работе, называвшейся «Аналитическая смесь», Муавр дал первый вариант теоремы Муавра—Лапласа, исследующей распределение возможных отклонений статистической частоты от вероятности. Муавр рассмотрел только случай, когда вероятность равна 1/2, общий же случай для любой вероятности доказал Лаплас[30]. Ещё одним достижением Муавра стало первое введение в науку нормального распределения (1733), которое появилось у него как аппроксимация биномиального распределения[31]. Даниил Бернулли, племянник основателя теории вероятностей, также внёс вклад в эту науку. Он, независимо от Муавра, исследовал нормальное распределение для ошибок наблюдений, первым применил к вероятностным задачам методы математического анализа, опубликовал первый из вероятностных парадоксов (1738)[32]. Следующий важный шаг сделал английский математик Томас Симпсон, который в ходе занятий численным анализом в книге «Природа и законы случая» (1740) фактически использовал третье (наряду с классическим и статистическим) определение вероятности — геометрическое, пригодное для исследования непрерывных случайных величин с бесконечным числом значений. В задаче XXVI Симпсон нашёл вероятность того, что наудачу брошенный на плоскость параллелепипед остановится на заданной своей грани[33].   Задача об игле Бюффона Подход Симпсона развил Жорж-Луи де Бюффон, который в 1777 году привёл классический пример задачи на геометрическую вероятность[31]. Это была занимавшая впоследствии многих математиков «задача Бюффона о бросании иглы»: плоскость разграфлена «в линейку», на неё наудачу бросается игла, требуется найти вероятность того, что игла пересечёт линию[33]. Если длина иглы     a   {\displaystyle a}   меньше, чем расстояние между линиями     l   {\displaystyle l}  , то искомая вероятность равна        2 a   π l      {\displaystyle {\frac {2a}{\pi l}}}  . Данная формула была несколько раз проверена экспериментально, в том числе самим Бюффоном, а в 1901 году итальянский математик Марио Лаццарини (Mario Lazzarini) использовал её для опытного определения числа     π   {\displaystyle \pi }  . Задача Бюффона, её анализ и различные модификации обсуждались математиками многие годы[34]. Была решена важнейшая задача расчёта вероятности для сложных событий. Английский математик Томас Байес первым в отчётливом виде привёл теорему сложения вероятностей для нескольких несовместимых событий и основополагающие в теории вероятностей и статистике «формулы Байеса» (1763 год, опубликованы посмертно). В современной терминологии формулы Байеса позволяют рассчитать условную вероятность, а также уточнить рассчитанную вероятность после получения новых данных. Теорему умножения вероятностей ранее открыл Муавр (1718 год) и дал ей вполне современную, хотя и словесную формулировку: «вероятность появления двух зависимых событий равна произведению вероятности появления одного из них на вероятность того, что другое должно появиться, если первое из них уже появилось»[35]. К середине XVIII века анализ игр всё ещё привлекает некоторый интерес — например, Леонард Эйлер дал подробный анализ разных типов лотерей[36], но центром внимания математиков всё в большей степени становятся демографическая статистика, страхование и оценка ошибок (измерения, округления и т. п.). Статистике и страхованию Эйлер посвятил немало работ; он, в частности, решал задачу: оценить по статистическим таблицам, какова вероятность того, что человек в возрасте     m   {\displaystyle m}   лет проживёт ещё     n   {\displaystyle n}   лет[37].  XIX век[править | править код] Общие тенденции и критика[править | править код] В XIX веке число работ по теории вероятностей продолжало расти, были даже компрометирующие науку попытки распространить её методы далеко за разумные пределы — например, на область морали, психологии, правоприменения и даже богословия[38]. В частности, валлийский философ Ричард Прайс, а следом за ним и Лаплас, считали возможным рассчитать по формулам Байеса вероятность предстоящего восхода Солнца[39], Пуассон пытался провести вероятностный анализ справедливости судебных приговоров и достоверности показаний свидетелей[40]. Философ Дж. С. Милль в 1843 году, указав на подобные спекулятивные применения, назвал исчисление вероятностей «позором математики»[41]. Эта и другие оценки свидетельствовали о недостаточной строгости обоснования теории вероятностей. Математический аппарат теории вероятностей тем временем продолжал совершенствоваться. Основной сферой её применения в тот период была математическая обработка результатов наблюдений, содержащих случайные погрешности, а также расчёты рисков в страховом деле и других статистических параметров. Среди главных прикладных задач теории вероятностей и математической статистики XIX века можно назвать следующие[42]:  найти вероятность того, что сумма независимых случайных величин с одинаковым (известным) законом распределения находится в заданных пределах. Особую важность эта проблема представляла для теории ошибок измерения, в первую очередь для оценки погрешности наблюдений; установление статистической значимости различия случайных значений или серий таких значений. Пример: сравнение результатов применения нового и старого видов лекарств для принятия решения о том, действительно ли новое лекарство лучше; исследование влияния заданного фактора на случайную величину (факторный анализ). Уже к середине XIX века формируется вероятностная теория артиллерийской стрельбы. В большинстве крупных стран Европы были созданы национальные статистические организации. В конце века область применения вероятностных методов начала успешно распространяться на физику, биологию, экономику, социологию[43][44].  Гаусс, Лаплас, Пуассон[править | править код]  С увеличением числа n бросков игральной кости сумма выпавших очков стремится к нормальному распределению Карл Фридрих Гаусс, постоянно занимавшийся астрономическими вычислениями, разработал вероятностную методику работы с измерениями, содержащими погрешности (1809). Он глубоко изучил нормальное распределение, показал, что оно во многих практических ситуациях является предельным для случайных значений, обосновал применение метода наименьших квадратов для оценки измеряемого значения и параметров его возможного диапазона разброса. Окончательную версию теории Гаусс изложил в двух трудах «Теория комбинации наблюдений, подверженных случайным ошибкам» (1823, 1828)[45]. Хотя нормальный закон был известен задолго до Гаусса, его вклад в теорию этого важнейшего распределения настолько велик, что долгое время нормальный закон называли «законом Гаусса»; современный термин закрепился благодаря работам Карла Пирсона в конце XIX века[44]. Основные достижения теории вероятностей подытожены в капитальной монографии Лапласа «Аналитическая теория вероятностей» (1812 год), которая завершила «классический этап» развития этой науки. В XIX веке труд Лапласа выдержал во Франции три переиздания и был переведён на многие языки мира[43]. Лаплас исследовал как дискретные, так и непрерывные случайные величины (ещё не вводя термина «случайная величина»), причём для непрерывных дал ключевое понятие плотности распределения вероятности, ранее неявно и ограниченно использованное Даниилом Бернулли. Интегральное понятие функции распределения возникло гораздо позже (его в 1912 году ввёл А. М. Ляпунов); общий термин «случайная величина» также, по-видимому, впервые появился в работах русской вероятностной школы[46]. Введение плотности вероятности и характеристических функций позволило Лапласу применить для решения вероятностных задач мощные аналитические средства, включая дифференциальные уравнения в частных производных[40]. Лаплас привёл формулу полной вероятности для нескольких несовместных «причин» (в современной терминологии, «гипотез»), доказал ряд предельных теорем, в том числе теорему Муавра—Лапласа и сходимость биномиального распределения к нормальному при увеличении числа испытаний. Значительная часть книги посвящена статистическим приложениям и решению задач. Для оценки возможного диапазона значений измеряемой величины Лаплас, как и Гаусс, рекомендовал метод наименьших квадратов[47]. Лаплас описал и своё понимание сущности случайности и вероятности. По его мнению, ход реальных процессов полностью предопределён («детерминирован»), случайность появляется лишь в человеческом восприятии и только там, где человек не владеет полным знанием происходящего[48]:      Ум, которому были бы известны для какого-либо данного момента все силы, одушевляющие природу, и относительное положение всех её составных частей, если бы вдобавок он оказался достаточно обширным, чтобы подчинить эти данные анализу, обнял бы в одной формуле движение величайших тел вселенной наравне с движениями легчайших атомов; не осталось бы ничего, что было бы для него недостоверно, и будущее, так же, как и прошедшее, предстало бы пред его взором. Симеон Дени Пуассон в 1837 году обобщил закон больших чисел Бернулли, сняв условие о том, что вероятность события в каждой игре одна и та же; при этих новых условиях статистическая частота будет сходиться к среднему арифметическому для вероятностей отдельных игр[49]. Он же опубликовал формулу Пуассона, удобную для описания схемы Бернулли в том случае, когда вероятность события близка к нулю или к единице. Распределение Пуассона («закон редких событий») является одним из основных в прикладных задачах, например, ему подчиняются радиоактивный распад, рождение тройни, статистика аварий и несчастных случаев[50].  Теория ошибок измерения[править | править код] Основная проблема в этой области следующая. Пусть последовательные измерения некоторой величины дали     n   {\displaystyle n}   близких, но неравных значений. Подразумевается, что систематические ошибки и зависимость величины от времени измерения (скажем, при вращении небесного свода) учтены, так что различие данных вызвано чисто случайными погрешностями. Надо по результатам измерений найти наилучшую оценку истинного значения исследуемой величины[51]. Первое математическое исследование этой практически важной (особенно в астрономии) темы предпринял Томас Симпсон (1755). Он исходил из неверной гипотезы, что ошибки измерения распределены по «треугольному закону», но сделал правильный вывод — среднее арифметическое результатов измерения ближе к истинному значению, чем отдельное измерение. Даниил Бернулли (1778) считал, что плотность распределения ошибок представляет собой дугу окружности, но вывод Симпсона подтвердил[52]. Идеи Симпсона развил И. Г. Ламберт, впервые применивший метод производящих функций и метод максимального правдоподобия, позднее обобщённый Р. Э. Фишером[53]. В XIX веке Лаплас указал, что наблюдаемые погрешности измерения являются обычно результатом суммирования множества случайных ошибок, и поэтому их распределение должно быть близко к нормальному. Вместо среднего арифметического он предложил статистическую медиану. Однако почти одновременно был опубликован гораздо более практичный метод наименьших квадратов Гаусса (1809), который и стал общеупотребительным. В 1853 году Коши обнаружил пример распределения, для которого среднее арифметическое является очень плохой оценкой. К концу XIX века статистическая теория обработки ошибок была в основном завершена[52].  Парадоксы Бертрана[править | править код] В 1889 году французский математик Жозеф Бертран в своём курсе «Анализ вероятностей» предложил ряд парадоксов, связанных с геометрической вероятностью. В каждом парадоксе разное истолкование понятий «наудачу» или «взятое произвольно» приводило к разным решениям задачи. Пример одного из парадоксов Бертрана: найти вероятность того, что выбранная наудачу хорда окружности окажется длиннее стороны вписанного в эту окружность треугольника. При разных методах выбора хорды «наудачу» получаются разные ответы.      Метод 1       Метод 2       Метод 3     Обсуждение парадоксов Бертрана содействовало уточнению оснований теории вероятностей и смысла термина «равновероятно»[54].  Статистическая физика[править | править код]  Людвиг Больцман До середины XIX века практическое применение теории вероятностей было в основном ограничено статистикой и приближёнными вычислениями, поэтому общий термин «случайная величина» появился довольно поздно[55]. Одним из первых случайных процессов в физике стало изученное Робертом Броуном в 1827 году под микроскопом хаотическое движение цветочной пыльцы, плававшей в воде («броуновское движение»). Его математическая модель, однако, появилась только в начале XX века (А. Эйнштейн, М. Смолуховский, Н. Винер)[56]. Первые физические вероятностные модели возникли в статистической физике, которую разработали во второй половине XIX века Л. Больцман, Д. К. Максвелл и Д. У. Гиббс. Больцман в серии работ (1860-е годы) показал, что термодинамические законы имеют вероятностно-статистический характер и связаны с переходом физических систем из менее вероятного состояния в более вероятное, причём мерой вероятности является энтропия. Максвелл в эти же годы вывел закон распределения скоростей молекул в газе, который позволяет рассчитать энергию, длину свободного пробега и другие характеристики молекул. В 1902 году Гиббс опубликовал монографию «Основные принципы статистической механики», оказавшую большое влияние на развитие физики[57]. К концу XIX века огромное практическое значение вероятностных методов стало общепризнанным фактом.  Российская школа[править | править код] В России в первой половине XIX века начали возникать собственные серьёзные исследования по теории вероятностей. Первый учебный курс начал читать С. Ревковский в Вильнюсском университете (1829 год), там же в 1830 году была создана первая в Российской империи кафедра теории вероятностей. В Петербургском университете лекции с 1837 года читал сначала В. А. Анкудович, а с 1850 года — В. Я. Буняковский. Фундаментальный учебник «Основания математической теории вероятностей» Буняковский опубликовал в 1846 году, и придуманная им русская терминология стала общепринятой. В Московском университете курс появился в 1850 году, лекции читал А. Ю. Давидов, будущий президент Московского математического общества[58]. Статьи по вероятностным темам публиковали многие крупные математики России, в том числе М. В. Остроградский, Н. Д. Брашман, Н. И. Лобачевский, Н. Е. Зернов. В значительной части этих работ ощущается сильное влияние трудов и взглядов Лапласа[59].   П. Л. Чебышёв Первыми русскими математиками мирового уровня в теории вероятностей стали П. Л. Чебышёв и его ученики А. А. Марков и А. М. Ляпунов. Чебышёв с самого начала своей научной карьеры уделял наибольшее внимание теории вероятностей (наряду с теорией чисел), а с 1860 года сменил Буняковского на кафедре теории вероятностей и начал свой цикл лекций. Он опубликовал по данной теме всего четыре работы, но фундаментального характера. Особенно интересна его статья «О средних величинах» (1866 год), где приведено «неравенство Чебышёва», позднее усиленное Марковым:       P   (   |  x − M x  |  ⩾ k σ  )  ⩽   1  k  2       {\displaystyle \mathbb {P} \left(|x-Mx|\geqslant k\sigma \right)\leqslant {\frac {1}{k^{2}}}}  .  Неравенство Чебышёва, ограничивающее вероятность больших отклонений случайной величины от своего математического ожидания Эта формула означает, что вероятность отклонения любой случайной величины     x   {\displaystyle x}   от её среднего значения (математического ожидания)     M x   {\displaystyle Mx}   более чем на     k   {\displaystyle k}   стандартных отклонений (    σ   {\displaystyle \sigma }  ) не превышает       1  k  2       {\displaystyle {\frac {1}{k^{2}}}}  . Например, отклонение на 5     σ   {\displaystyle \sigma }   имеет вероятность не более 1/25, то есть не более 4 %. В качестве следствия своего неравенства Чебышёв получил чрезвычайно общую формулировку закона больших чисел: если математические ожидания серии     n   {\displaystyle n}   случайных величин и квадраты этих математических ожиданий ограничены в совокупности, то среднее арифметическое этих величин с ростом     n   {\displaystyle n}   сходится к среднему арифметическому для их математических ожиданий. Из этой теоремы получаются как следствия теоремы Бернулли и Пуассона; Чебышёв впервые строго оценил точность этих теорем и других приближений[60]. В 1887 году появилась статья Чебышёва «О двух теоремах относительно вероятностей». В этой работе он установил, что при некоторых (достаточно общих) условиях выполняется предельная теорема: сумма большого числа независимых случайных величин (например, погрешностей измерения) распределена приближённо по нормальному закону и тем точнее, чем больше слагаемых. Этот результат по своей общности далеко перекрывает теорему Муавра — Лапласа и все её аналоги[61]. Позже А. А. Марков и А. М. Ляпунов уточнили и ещё более обобщили данную теорему Чебышёва. Обе упомянутые теоремы Чебышёва занимают центральное место в теории вероятностей. Особенно важно то обстоятельство, что Чебышёв не только указал предельное распределение, но в обоих случаях детально проанализировал границы возможных отклонений от этого предела[5]. Если Чебышёв исследовал независимые случайные величины, то А. А. Марков в 1907 году расширил поле исследований, рассматривая и случай, когда новое случайное значение зависит от старого. Марков доказал вариант закона больших чисел для некоторых распространённых типов зависимых величин, введя в терминологию мировой науки «цепи Маркова». Анализу и классификации этих цепей Марков посвятил немало работ; цепи Маркова и марковские случайные процессы применяются не только в математике, но и в других науках, таких как статистическая физика, квантовая механика, теория автоматического управления и многие другие[62]. Маркову принадлежит также вероятностное обоснование метода наименьших квадратов[63]. А. М. Ляпунову принадлежит введение метода характеристических функций в учение о предельных теоремах теории вероятностей[63].  XX век[править | править код] Теоретические вопросы и математические методы[править | править код] В XX веке исследования Чебышёва и Маркова продолжили А. Я. Хинчин, А. Н. Колмогоров и др. В частности, Ярл В. Линдеберг (1922) и Колмогоров (1926) нашли условия, необходимые и достаточные для выполнения закона больших чисел[64]. Математический аппарат теории вероятностей значительно обогатился во многих направлениях. После разработки теории меры это общее понятие оказалось удобно применить к теории вероятностей, то есть рассматривать вероятность как меру (конечного или бесконечного) множества «благоприятных событий». Такой подход позволяет описывать и исследовать свойства вероятности на хорошо разработанном языке теории множеств[65].   Хаотическое движение в задаче трёх тел (компьютерное моделирование) В теории динамических систем было обнаружено, что решения дифференциальных уравнений некоторых систем ведут себя как случайные процессы. Это крупное открытие привело к созданию понятия «динамический хаос» и общей «теории хаоса». Одним из примеров является «задача трёх тел» небесной механики[66]. До XX века использовались в основном нормальное, биномиальное и (иногда) пуассоновское распределения, однако практически полезными оказались и многие другие теоретические законы. Например, логнормальное распределение часто встречается в ситуациях, когда исследуемая величина есть произведение нескольких независимых положительных случайных величин[67]. Вероятностные методы оказались плодотворными во многих областях теоретической и прикладной математики, даже в таких классических, как теория чисел[68] или логика[69]. В свою очередь, современная теория вероятностей использует методы и подходы, разработанные в функциональном анализе, топологии и других разделах математики, появившихся в XX веке[70].  Создание математической статистики[править | править код]  Карл Пирсон Применением в статистике математических методов, в том числе специально разработанных для этой цели, занимались многие учёные, от Гюйгенса и Лапласа до Кетле и Гальтона. Математическая статистика как основа для принятия надёжных решений о случайных величинах возникла на рубеже XIX—XX веков благодаря основополагающим работам Карла Пирсона, ученика Гальтона. Пирсон разработал теорию корреляции, критерии согласия, регрессионный анализ, алгоритмы проверки гипотез, принятия решений и оценки параметров[71]. Алгоритмы, предложенные Пирсоном, находят широкое применение в физике, медицине, биологии, социологии, сельском хозяйстве и др.[72] Виднейшим продолжателем работ Пирсона по прикладной математической статистике в первой половине XX века стал Рональд Эйлмер Фишер. Он опубликовал работы по планированию эксперимента, разработал метод максимального правдоподобия, тест статистической значимости, дисперсионный анализ и решение ряда других практически важных статистических проблем. Совместно с Ежи Нейманом разработал концепцию доверительного интервала (1937). Фишер — автор общепризнанного термина «дисперсия случайной величины» (англ. variance)[73]. Начиная примерно с 1920-х годов, быстро развивается теория статистического контроля качества промышленной продукции. Первую проблему по этой теме рассмотрел ещё Томас Симпсон в 1846 году. В массовом производстве надо определить, по какой методике следует изъять предметы из одной или нескольких партий продукции для проверки их качества[74]. Изобилие в наши дни статистических исследований, нередко дающих противоположные результаты (например, о наличии или отсутствии вреда от мобильных телефонов или генно-модифицированных продуктов), сделало актуальной и часто обсуждаемой проблему обеспечения достоверных выводов из статистического обследования. Наиболее частая ошибка — объявление, что статистическая зависимость (корреляция) изучаемых факторов якобы свидетельствует о причинной связи между ними, хотя часто связь этих факторов реально объясняется их зависимостью от одного или нескольких третьих факторов[75]. «Статистическая зависимость, как бы ни была она сильна, никогда не может установить причинной связи: наши идеи о причине должны приходить извне статистики, в конечном счёте из некоторой другой теории»[76].  Случайные процессы[править | править код]  Запись случайного процесса (белый шум) Понятие случайного (или стохастического) процесса, возникшее в начале XX века, стало одним из центральных, быстро развивающихся и наиболее полезных применений теории вероятностей. Случайный процесс — это переменная во времени случайная величина. Первые исследования случайных процессов касались в основном электроники и сообщений теории связи, в наши дни можно привести в качестве примеров временные ряды в экономике или медицине, регистрограммы теории механизмов, статистику жизни биологии популяций. Широкую сферу практического применения имеет теория массового обслуживания. Среди типовых задач анализа случайных процессов[77]:  прогнозирование развития процесса, исходя из его прошлой истории; надёжное выделение сигнала на фоне шумовых помех; оценка и оптимизация параметров (например, вероятного времени безотказной работы); фильтрация входного случайного процесса для получения желаемого выходного процесса. Проведена классификация типов случайных процессов, разработаны аналитические средства их исследования (корреляционная и ковариационная функции, спектральное разложение)[78][79]. Для анализа процессов разработаны такие новые средства, как стохастические дифференциальные уравнения, стохастический интеграл, средства спектрального анализа и фильтрации[80].  Новые приложения[править | править код] Новые применения вероятностных методов возникали в XX веке постоянно и во многих науках; кратко перечислим некоторые этапные события в этой тенденции.  Физика Центральным понятием созданной в 1920-е годы квантовой механики является комплексная волновая функция, квадрат модуля которой, согласно распространённой копенгагенской интерпретации, определяет плотность вероятности обнаружения микрочастицы в данной точке пространства. Если принять такую интерпретацию, то в математической модели микромира случайность неустранима, а лапласовский детерминизм полностью опровергнут[81]. Для микромира были разработаны специальные квантовые статистики Бозе — Эйнштейна и Ферми — Дирака.  Биология После открытий Менделя и Моргана стало понятно, что наследственные признаки передаются потомкам путём случайной комбинации одного из двух признаков (аллелей) от отца и одного из двух аналогичных аллелей от матери. Случайный выбор аллели отца определяет заодно пол будущего потомка. На этот процесс дополнительно накладываются случайные мутации, поэтому вероятностные методы легли в основу генетики. Применяются они также при исследовании и управлении развитием биологических популяций[82]. Существенно используются вероятностные подходы (например, байесовские методы и методы, основанные на принципе наибольшего правдоподобия) в вычислительной филогенетике[en], предусматривающей применение специальных вычислительных алгоритмов и компьютерных программ для построения филогенетических деревьев[83][84].  Кибернетика и теория информации Теория информации опирается на введённое Клодом Шенноном в 1948 году понятие информационной энтропии[85]. Если случайная величина     x   {\displaystyle x}   может принимать значения      x  1   ,  x  2   , …  x  n     {\displaystyle x_{1},x_{2},\dots x_{n}}  , вероятности которых соответственно равны      p  1   ,  p  2   , …  p  n     {\displaystyle p_{1},p_{2},\dots p_{n}}  , то энтропия определяется формулой:      H ( x ) = −  ∑  i = 1   n    p  i    log  2   ⁡  p  i     {\displaystyle H(x)=-\sum _{i=1}^{n}p_{i}\log _{2}p_{i}}  . Определённая так энтропия есть мера случайности (или неопределённости): она равна нулю, если случайность отсутствует, то есть с вероятностью 1 величина принимает одно определённое значение. Увеличение случайности связано с увеличением энтропии[86]. Теория автоматического управления также изначально использовала вероятностные методы. С появлением компьютеров применение таких методов многократно расширилось. Используя генератор псевдослучайных чисел, можно промоделировать на компьютере случайные величины или процессы с произвольным распределением, а это, в свою очередь, позволяет исследовать самые разные реальные процессы путём их компьютерного моделирования (метод Монте-Карло)[87].  Лингвистика Во 2-й половине XX века в важное направление математической лингвистики оформилось применение методов теории вероятностей и математической статистики к изучению лингвистических явлений. Многочисленные исследования, основанные на применении таких методов, включали: получение вероятностно-информационных оценок нормы языка; анализ распределения синтактической информации в пределах словоформы, контекстной обусловленности и избыточности текстов, взаимодействия случайных и детерминированных процессов в речи; разработку адекватных методик лингвистического эксперимента; выявление статистических характеристик лингвистических вариационных рядов и др.[88]  Обоснование и аксиоматизация[править | править код] К моменту создания теории вероятностей основой математики были два класса объектов — числа и геометрические фигуры. Для теории вероятностей потребовалось добавить в этот список совершенно особый объект: случайное событие, а также тесно связанные с ним понятия (вероятность, случайная величина и др.). Своеобразие новой науки проявлялось и в том, что её утверждения носили не безусловный характер, как ранее было принято в математике, а предположительно-вероятностный. По мере развития теории вероятностей не прекращались споры о том, можно ли считать идеализированное событие математическим понятием (и тогда теория вероятностей есть часть математики) или же это факт, наблюдаемый в опыте (и тогда теорию вероятностей следует отнести к естественным наукам). Разные учёные высказывали самые разные мнения на этот счёт. П. Л. Чебышёв уверенно считал теорию вероятностей математической дисциплиной, задача которой — по известным вероятностям некоторых событий определить неизвестную вероятность исследуемого события. По мнению Давида Гильберта, теория вероятностей родственна механике, то есть представляет собой математизированную «физическую дисциплину»[41]. Август де Морган и его последователь У. С. Джевонс считали базовым понятием «субъективную вероятность», то есть количественную меру нашего понимания предмета исследования, и связывали теорию вероятностей с логикой[89]. Проблемы, связанные с неоднозначной субъективной вероятностью, неоднократно обсуждались, их часто формулируют в виде «вероятностных парадоксов» (см., например, «парадокс трёх узников» или «парадокс мальчика и девочки»). Формализацию субъективной вероятности, совместимую с колмогоровской, предложили Бруно де Финетти (1937) и Леонард Сэвидж (1954). Ещё Бернулли дал фактически два определения вероятности: как доли «благоприятных случаев» и как статистической частоты; чтобы свести второе понимание к первому, понадобился закон больших чисел. Австрийский математик и механик Рихард фон Мизес предложил обратный подход (1914 год): считать определением вероятности именно предел частоты. Теорию вероятностей Мизес к математике не относил, он считал её опытной наукой, изучающей наблюдаемые факты[41]. Определение Мизеса и изложенная им аксиоматика подверглись критике за бессодержательность, поскольку не существует средств для выяснения, имеет ли частота заданного события предел[90]. Обсуждение концепции Мизеса иногда продолжается и в наши дни[91]. Были и другие попытки обоснования — Джон Мейнард Кейнс (1921) и Гарольд Джеффрис (1939) предложили понимать вероятность утверждения как «степень правдоподобия» этого утверждения, этот подход также время от времени упоминается в обсуждении вопроса[92].   А. Н. Колмогоров В начале XX века школа Д. Гильберта поставила такие классические разделы математики, как геометрия и анализ, на строгую аксиоматическую основу, появилась аксиоматика и в других разделах математики: теория множеств, математическая логика и др. Назрела необходимость разработать аксиоматику и для теории вероятностей, поскольку старое, полуинтуитивное и неформальное обоснование Бернулли и Лапласа давно устарело. Первый вариант такой аксиоматики дал советский математик С. Н. Бернштейн в своём курсе «Теория вероятностей» (1927 год). Общепризнанным в науке стал вариант А. Н. Колмогорова, опубликованный в 1929—1933 годах и основанный на идеях теории меры[93]. Во второй половине XX века Альфред Реньи и А. Н. Колмогоров исследовали возможность дать обоснование теории вероятностей на базе теории информации[94]. В наши дни «сложилось чёткое понимание того, что теория вероятностей является подлинно математической наукой, имеющей вместе с тем самые тесные и непосредственные связи с широким спектром наук о природе, а также с техническими и социально-экономическими дисциплинами»[95]. Несмотря на доказанную практикой эффективность вероятностных методов, роль случайности в природе, причина и границы статистической устойчивости остаются предметом дискуссий[96]. «За 200 лет, прошедших со времен Лапласа и Гаусса, наука не добилась продвижения в фундаментальном вопросе — когда возникает статистическая устойчивость»[97].  См. также[править | править код] Вероятностная логика Вероятностное пространство Вероятностные парадоксы Риск Стохастичность Примечания[править | править код]   ↑ Гнеденко Б. В. О работах М. В. Остроградского по теории вероятностей // Историко-математические исследования. — М.: ГИТТЛ, 1951. — № 4. — С. 120.  ↑ Гнеденко Б. В. Очерки по истории математики в России. — М.—Л.: ОГИЗ, 1946. — С. 201.  ↑ Майстров Л. Е., 1967, с. 303.  ↑ Вентцель Е. С. Теория вероятностей. — Изд. 4-е, стереотипное. — М.: Наука, 1969. — С. 17. — 577 с.  ↑ 1 2 Колмогоров А. Н. Роль русской науки в развитии теории вероятностей // Учёные записки МГУ. — Μ., 1947. — Т. I, вып. 91, кн.1. — С. 53—64.  ↑ Шейнин О. Б., 1978, с. 284—285.  ↑ Шейнин О. Б., 1978, с. 285—288.  ↑ Гнеденко Б. В., 2005, с. 366.  ↑ Майстров Л. Е., 1967, с. 22.  ↑ Гнеденко Б. В., 2005, с. 368.  ↑ 1 2 3 4 5 Реньи А. Об истории теории вероятностей // Реньи А.  Трилогия о математике. — М.: Мир, 1980. — 376 с. — С. 184—186.  ↑ Майстров Л. Е., 1967, с. 23—31.  ↑ Гнеденко Б. В., 2005, с. 370—371.  ↑ Майстров Л. Е. Элементы теории вероятностей у Галилея // Вопросы истории естествознания и техники. — Μ.: Наука, 1964. — Вып. 16. — С. 94—98.  ↑ 1 2 3 Стройк Д. Я., 1984, с. 143.  ↑ Ван дер Варден Б. Л. Переписка между Паскалем и Ферма по вопросам теории вероятностей // Историко-математические исследования. — М.: Наука, 1976. — № 21. — С. 228—232.  ↑ Гнеденко Б. В., 2005, с. 375—376, 379.  ↑ 1 2 3 История математики, том II, 1970, с. 89—91.  ↑ Гнеденко Б. В., 2005, с. 379—380.  ↑ Гнеденко Б. В., 2005, с. 399—400.  ↑ Витерби Э. Д. Принципы когерентной связи. — М.: Советское радио, 1970. — С. 102. — 392 с.  ↑ Майстров Л. Е., 1967, с. 58—60.  ↑ Майстров Л. Е., 1967, с. 64—65.  ↑ Alter G. Plague and the Amsterdam Annuitant: A New Look at Life Annuities as a Source for Historical Demography // Population Studies, 37, 1983. — P. 23—41.  ↑ 1 2 Гнеденко Б. В., 2005, с. 387—389, 73.  ↑ Майстров Л. Е., 1967, с. 67—79.  ↑ Бернулли Я., 1986.  ↑ Майстров Л. Е., 1967, с. 81—89.  ↑ Гнеденко Б. В., 2005, с. 402.  ↑ Майстров Л. Е., 1967, с. 95—96.  ↑ 1 2 Стройк Д. Я., 1984, с. 175.  ↑ Никифоровский В. А., 1992, с. 48.  ↑ 1 2 Гнеденко Б. В., 2005, с. 390—391.  ↑ Badger L. Lazzarini’s Lucky Approximation of     π   {\displaystyle \pi }   // Mathematics Magazine, 67 (2), 1994. — P. 83—91. — DOI:10.2307/2690682.  ↑ Гнеденко Б. В., 2005, с. 394—397.  ↑ Майстров Л. Е., 1967, с. 119—125.  ↑ Гнеденко Б. В. О работах Леонарда Эйлера по теории вероятностей, теории обработки наблюдений, демографии и страхованию // К 250-летию со дня рождения Л. Эйлера. — Сборник. — Изд-во АН СССР, 1958.  ↑ Вентцель Е. С. Теория вероятностей. — Изд. 4-е, стереотипное. — М.: Наука, 1969. — С. 20. — 577 с.  ↑ История математики, том III, 1972, с. 138, 148—149, 151.  ↑ 1 2 Шейнин О. Б. Теория вероятностей П. С. Лапласа // Историко-математические исследования. — М.: Наука, 1977. — № 22. — С. 212—224.  ↑ 1 2 3 Григорян А. А. Теория вероятностей Р. фон Мизеса: история и философско-методологические основания // Историко-математические исследования. — М.: Янус-К, 1999. — № 38 (4). — С. 198—220.  ↑ История математики, том III, 1972, с. 149.  ↑ 1 2 История математики, том III, 1972, с. 150—151.  ↑ 1 2 Математика XIX века. Том I, 1978, с. 208, 239.  ↑ Майстров Л. Е., 1967, с. 178—187.  ↑ Гнеденко Б. В., 2005, с. 414.  ↑ Майстров Л. Е., 1967, с. 167—175.  ↑ Майстров Л. Е., 1967, с. 163.  ↑ Майстров Л. Е., 1967, с. 187—189.  ↑ Никифоровский В. А., 1992, с. 113—114.  ↑ Щиголев Б. М. Математическая обработка наблюдений. — Изд. 2-е, стереотипное. — М.: Физматлит, 1962. — С. 209—215. — 344 с.  ↑ 1 2 Гнеденко Б. В., 2005, с. 408—411.  ↑ История математики, том III, 1972, с. 134.  ↑ Майстров Л. Е., 1967, с. 279—285.  ↑ Гнеденко Б. В., 2005, с. 417—418.  ↑ Спасский Б. И. История физики. — М.: Высшая школа, 1977. — Т. II. — С. 74—75.  ↑ Майстров Л. Е., 1967, с. 268—276.  ↑ Майстров Л. Е., 1967, с. 191—197, 204—213.  ↑ Майстров Л. Е., 1967, с. 197—204, 214.  ↑ Майстров Л. Е., 1967, с. 225—238.  ↑ Чебышёв П. Л.  Полное собрание сочинений. — Изд-во АН СССР, 1948. — Т. III. — С. 404.  ↑ Майстров Л. Е., 1967, с. 253—259.  ↑ 1 2 Стройк Д. Я., 1984, с. 255.  ↑ Майстров Л. Е., 1967, с. 310—311.  ↑ Чернова Н. И. Мера и вероятностная мера (неопр.). Проверено 11 января 2014.  ↑ Тихомиров В. Математика во второй половине XX века // Квант. — 2001. — № 1.  ↑ Логарифмически нормальное распределение // Математическая энциклопедия (в 5 томах). — М.: Советская Энциклопедия, 1982. — Т. 3.  ↑ Постников А. Г. Вероятностная теория чисел. — М.: Знание, 1974. — 63 с.  ↑ Вероятностная логика (неопр.). Проверено 10 января 2014.  ↑ Теория вероятностей // Математика в СССР за сорок лет, 1917—1957. — М.: Физматгиз, 1959. — Т. I.  ↑ Джон Дж. О’Коннор и Эдмунд Ф. Робертсон. Пирсон, Карл (англ.) — биография в архиве MacTutor.  ↑ Porter, T. M. Karl Pearson: The Scientific Life in a Statistical Age. — Princeton University Press, 2004. — ISBN 978-0-691-12635-7.  ↑ The correlation between relatives on the supposition of Mendelian Inheritance (неопр.) (1918). Проверено 29 декабря 2013.  ↑ Гнеденко Б. В., 2005, с. 403—405.  ↑ Майерс Дэвид Дж. Корреляция или причинно-следственная связь (неопр.). Проверено 6 января 2014.  ↑ Кендалл М., Стьюарт А. Статистические выводы и связи. — М.: Наука, 1972. — С. 374. — 900 с.  ↑ Розанов Ю. А. Случайные процессы. Краткий курс. — Изд. 2-е, перераб. и дополн. — М.: Наука, 1979. — С. 174—183. — 184 с.  ↑ Гнеденко Б. В., 2005, с. 430—434.  ↑ Корн Г., Корн Т. Справочник по математике (для научных работников и инженеров). — М.: Наука, 1973. — С. 522—534. — 720 с.  ↑ Розанов Ю. А. Теория вероятностей, случайные процессы и математическая статистика. — М.: Наука, 1985. — С. 236—282. — 320 с.  ↑ Детлаф А. А., Яворский Б. М. Курс физики. Учебное пособие. — Изд. 2-е. — М.: Высшая школа, 1999. — С. 514. — 719 с. — ISBN 5-06-003556-5.  ↑ Теория вероятностей и математическая статистика. Математические модели: учеб. пособие по направлению «Биология». — Μ.: Академия, 2009. — 315 с. — ISBN 978-5-7695-4704-1.  ↑ Kolaczkowski B., Thornton J. W. Long-Branch Attraction Bias and Inconsistency in Bayesian Phylogenetics // PLoS One, 4 (12), 2009. — P. e7891. — DOI:10.1371/journal.pone.0007891.  ↑ Simmons M. P. Misleading Results of Likelihood-based Phylogenetic Analyses in the Presence of Missing Data // Cladistics, 28 (2), 2012. — P. 208—222. — DOI:10.1111/j.1096-0031.2011.00375.x.  ↑ Информации теория (неопр.).  Энциклопедия «Кругосвет». Проверено 29 декабря 2013.  ↑ Волькенштейн М. В. Энтропия и информация. — М.: Наука, 2006. — 325 с.  ↑ Соболь И. М. Метод Монте-Карло. — Μ.: Наука, 1968. — (Популярные лекции по математике, вып. 46).  ↑ Пиотровский Р. Г., Бектаев К. Б., Пиотровская А. А.  Математическая лингвистика. — М.: Высшая школа, 1977. — 383 с. — С. 8—10, 110, 142, 189, 205—207, 233.  ↑ Математика XIX века. Том I, 1978, с. 238—239.  ↑ Хинчин А. Я. Частотная теория Р. Мизеса и современные идеи теории вероятности // Вопросы философии. — 1961. — С. 91—102 (вып. 1), 77—89 (вып. 2).  ↑ Гнеденко Б. В., 2005, с. 407.  ↑ Robert C. P., Chopin N., Rousseau J. Harold Jeffreys’s Theory of Probability Revisited // Statistical Science, 24 (2), 2009. — P. 141—172.  ↑ Майстров Л. Е., 1967, с. 297—302, 311—313.  ↑ Гнеденко Б. В., 2005, с. 407—408.  ↑ Математика XIX века. Том I, 1978, с. 240.  ↑ Алимов Ю. И., Кравцов Ю. А. Является ли вероятность «нормальной» физической величиной? // Успехи физических наук. — М., 1992. — № 162 (7). — С. 149—182.  ↑ Тутубалин В. Н. Вероятность, компьютеры и обработка результатов эксперимента // Успехи физических наук. — М., 1993. — № 163 (7). — С. 93—109.   Литература[править | править код] Труды основоположников Бернулли Я.  О законе больших чисел. — Μ.: Наука, 1986. — 176 с. Гаусс К. Ф.  Избранные геодезические сочинения. Т. 1. Метод наименьших квадратов. — Μ.: Изд-во геодезической литературы, 1957. — 234 с. Лаплас П. С.  Опыт философии теории вероятностей. 2-е изд. — Μ.: URSS, 2011. — 208 с. — (Физико-математическое наследие: математика (философия математики)). — ISBN 978-5-397-01695-7. Марков А. А.  Избранные труды. Теория чисел. Теория вероятностей. — Л.: Изд-во АН СССР, 1951. — 719 с. Реньи А.  Письма о вероятности: письма Паскаля к Ферма. — Μ.: Мир, 1970. — 96 с. Рецензия: Майстров Л. Е.  О вероятностной концепции Паскаля у А. Реньи // Историко-математические исследования. — Μ.: Наука, 1977. — № 22. — С. 200—211. Хрестоматия по истории математики. Математический анализ. Теория вероятностей / Под ред. А. П. Юшкевича. — М.: Просвещение, 1977. — 224 с. Чебышёв П. Л.  Теория вероятностей. Лекции акад. П. Л. Чебышёва, читанные в 1879/1880 годах. — М.—Л.: Изд-во АН СССР, 1936. — 253 с. Современные исследования Вилейтнер Г.  История математики от Декарта до середины XIX столетия. — М.: ГИФМЛ, 1960. — 468 с. Гнеденко Б. В.  К истории основных понятий теории вероятностей // История и методология естественных наук. — М.: Изд. МГУ, 1986. — Вып. XXXII. Математика, механика. — С. 81—88. Гнеденко Б. В.  Очерк по истории теории вероятностей // Курс теории вероятностей. 8-е изд. — Μ.: Едиториал УРСС, 2005. — 448 с. — ISBN 5-354-01091-8. — С. 366—435. Математика XIX века. Математическая логика, алгебра, теория чисел, теория вероятностей. Том I / Под ред. А. Н. Колмогорова, А. П. Юшкевича. — М.: Наука, 1978. — 255 с. Майстров Л. Е.  Теория вероятностей. Исторический очерк. — Μ.: Наука, 1967. — 321 с. История математики. Т. II. Математика XVII столетия / Под ред. А. П. Юшкевича. — М.: Наука, 1970. — 301 с. История математики. Т. III. Математика XVIII столетия / Под ред. А. П. Юшкевича. — М.: Наука, 1972. — 496 с. Никифоровский В. А.  Вероятностный мир. — М.: Наука, 1992. — С. 48. — (История науки и техники). — ISBN 5-02-003523-8. Стройк Д. Я.  Краткий очерк истории математики. — Изд. 3-е. — М.: Наука, 1984. — 285 с. Шейнин О. Б.  Теория вероятностей до П. Л. Чебышёва // Историко-математические исследования. — М.: Наука, 1978. — № 23. — С. 284—306. Ссылки[править | править код] Jui-Pin Cheng. The Origin of Probability and The Problem of Points (англ.) (2000). Проверено 30 декабря 2013. Glenn Shafer. The Early Development of Mathematical Probability (англ.). Проверено 30 декабря 2013. История математикиСтраны и эпохи Доисторический период Древний Египет Вавилон Древний Китай Древняя Греция Индия Армения Империя инков Страны ислама Россия Тематическиеразделы Алгебра Аналитическая геометрия Арифметика Вариационное исчисление Геометрия Дифференциальная геометрия и топология Комбинаторика Криптография Линейная алгебра Логарифмы Математический анализ Неевклидова геометрия Теория вероятностей Теория множеств Топология Тригонометрия Функциональный анализ См. также Бесконечно малые Вещественные числа Иррациональные числа Комплексные числа Математические обозначения Непрерывные дроби Отрицательные числа Функции  Эта статья входит в число избранных статей русскоязычного раздела Википедии.    