Функция потерь Хьюбера Функция потерь Хьюбера — это функция потерь, используемая в устойчивой регрессии, которая менее чувствительна к выбросам, чем квадратичная ошибка.  Определение[править | править код]  Функция потерь Хьюбера (заленый,     δ = 1   {\displaystyle \delta =1}  ) и квадратичная функция потерь (синий) как функция от     y − f ( x )   {\displaystyle y-f(x)}   Функция потерь Хьюбера задает штраф за процедуру оценки. Хьберт (1964) описал ее как кусочную функцию вида:[1]       L  δ   ( a ) =   {      1 2     a  2       для    |  a  |  ≤ δ ,     δ (  |  a  |  −   1 2   δ ) ,    иначе.          {\displaystyle L_{\delta }(a)={\begin{cases}{\frac {1}{2}}{a^{2}}&{\text{для }}|a|\leq \delta ,\\\delta (|a|-{\frac {1}{2}}\delta ),&{\text{иначе.}}\end{cases}}}   Эта функция квадратична для малых значений a, и линейна для больших значений, с одинаковым значением и уклоном для различных участков двух точек где      |  a  |  = δ   {\displaystyle |a|=\delta }  . Переменную a часто рассматривают как остаток, т.е как разницу между наблюдаемым и предсказанным значением     a = y − f ( x )   {\displaystyle a=y-f(x)}  , поэтому исходное определение может быть расширено до[2]:     L  δ   ( y , f ( x ) ) =   {      1 2   ( y − f ( x )  )  2      для    |  y − f ( x )  |  ≤ δ ,     δ   |  y − f ( x )  |  −   1 2    δ  2      иначе.          {\displaystyle L_{\delta }(y,f(x))={\begin{cases}{\frac {1}{2}}(y-f(x))^{2}&{\text{для }}|y-f(x)|\leq \delta ,\\\delta \,|y-f(x)|-{\frac {1}{2}}\delta ^{2}&{\text{иначе.}}\end{cases}}}    Примечания[править | править код]   ↑ Huber, Peter J. (1964). “Robust Estimation of a Location Parameter”. Annals of Statistics. 53 (1): 73—101. DOI:10.1214/aoms/1177703732. JSTOR 2238020..mw-parser-output cite.citation{font-style:inherit}.mw-parser-output q{quotes:"\"""\"""'""'"}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-lock-limited a,.mw-parser-output .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}  ↑ Hastie, Trevor. The Elements of Statistical Learning / Trevor Hastie, Tibshirani, Friedman. — 2009. — P. 349. Compared to Hastie et al., the loss is scaled by a factor of ½, to be consistent with Huber's original definition given earlier.      